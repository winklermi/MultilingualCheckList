{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList ACL 2020\n",
    "\n",
    "# One sentence summary:\n",
    "# Method to test the behaviour of NLP models through different experiments on small\n",
    "# manufactured example test sets.\n",
    "\n",
    "# Criticism:\n",
    "# The authors focus mainly on English NLP models and show that the CheckList analyses\n",
    "# uncover errors in commercial and openly available models. However, there is a wide usage\n",
    "# of multilingual models in the NLP community for multilingual or low-resource experiments\n",
    "# which makes an error analysis of multilingual models relevant and interesting.\n",
    "\n",
    "# Planned Implementation:\n",
    "# The plan is to take a multilingual model (e.g., mBERT) and create a Minimum Functionality\n",
    "# Test (MFT) for testing how the model handles negations in parallel Sentiment Analysis\n",
    "# sentences in English (like \"It was bad.\", \"It was good.\", \"It was not good.\"), German (\"Es war\n",
    "# schlecht.\", \"Es war gut.\", \"Es war nicht gut.\") and Bavarian (\"Des war schlecht.\", \"Des war\n",
    "# guad.\", \"Des war ned guad.\"). The experiments should then show whether the CheckList\n",
    "# methods can also be used in a multilingual setup and whether mBERT's behaviour changes\n",
    "# for different languages.\n",
    "\n",
    "# Feedback:\n",
    "# The proposal extends CheckList to other languages and implements a Minimum Functionality Test comparing English, German and Bavarian.\n",
    "# Looks good. Approved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# research questions:\n",
    "# can CheckList be applied to multilingual models? (only tested on English models)\n",
    "# can CheckList be used to compare model capabilities across languages? (here: has the model different behaviour when handling negations in different languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources\n",
    "\n",
    "# code for data creation partly taken from \n",
    "# https://github.com/marcotcr/checklist/blob/master/notebooks/tutorials/1.%20Generating%20data.ipynb\n",
    "# with major changes\n",
    "\n",
    "# code for test creation and execution partly taken from\n",
    "# https://github.com/marcotcr/checklist/blob/master/notebooks/tutorials/3.%20Test%20types%2C%20expectation%20functions%2C%20running%20tests.ipynb and\n",
    "# https://github.com/marcotcr/checklist/blob/master/notebooks/tutorials/4.%20The%20CheckList%20process.ipynb\n",
    "# with minor changes\n",
    "\n",
    "# code for model training taken partly from \n",
    "# https://huggingface.co/blog/sentiment-analysis-python\n",
    "# with minor changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# hard to find adjective pairs where standard German and Bavarian are different -> focus on only three pairs per sentiment\n",
    "\n",
    "# test sentences only work with predicative adjektive constructions to avoid issues with inflection of the pre-chosen adjectives in standard German and Bavarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.test_types import MFT\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise Editor objects\n",
    "eng_editor = Editor() # default language is English\n",
    "deu_editor = Editor(language=\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English adj suggestions: \n",
      "['great', 'good', 'wonderful', 'beautiful', 'fantastic', 'terrible', 'fascinating', 'big', 'nice', 'bad', 'long', 'fun', 'scary', 'terrific', 'tough', 'short', 'serious', 'huge', 'remarkable', 'new'] \n",
      "\n",
      "German adj suggestions: \n",
      "['gutes', 'neues', 'großes', 'kleines', 'starkes', 'politisches', 'anderes', 'wichtiges', 'ganzes', 'besonderes', 'altes', 'deutsches', 'eigenes', 'super', 'weiteres', 'solches', 'zweites', 'einziges', 'letztes', 'erstes']\n",
      "['guter', 'schlechter', 'großer', 'schöner', 'super', 'wichtiger', 'deutscher', 'schwieriger', 'historischer', 'neuer', 'kleiner', 'politischer', 'typischer', 'anderer', 'besonderer', 'amerikanischer', 'klassischer', 'einfacher', 'internationaler', 'langer']\n"
     ]
    }
   ],
   "source": [
    "# get adj suggestions from the CheckList Editors in German and English\n",
    "print(\"English adj suggestions: \")\n",
    "print(eng_editor.suggest(\"This is a {mask} {noun}.\", noun=[\"book\", \"movie\"])[:20], \"\\n\") \n",
    "\n",
    "print(\"German adj suggestions: \")\n",
    "print(deu_editor.suggest(\"Das ist ein {mask} Buch.\")[:20]) \n",
    "print(deu_editor.suggest(\"Das ist ein {mask} Film.\")[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel adjective lists for data creation\n",
    "eng_pos = [\"good\", \"nice\", \"great\"]\n",
    "deu_pos = [\"gut\", \"schön\", \"super\"]\n",
    "bar_pos = [\"guad\", \"schee\", \"subba\"]\n",
    "\n",
    "eng_neg = [\"bad\", \"boring\", \"stupid\"]\n",
    "deu_neg = [\"schlecht\", \"langweilig\", \"blöd\"]\n",
    "bar_neg = [\"schlecht\", \"fad\", \"bled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English noun suggestions: \n",
      "['game', 'one', 'stuff', 'book', 'article', 'video', 'post', 'movie', 'code', 'thing']\n",
      "['post', 'article', 'game', 'stuff', 'video', 'movie', 'list', 'shit', 'thing', 'book'] \n",
      "\n",
      "German noun suggestions: \n",
      "Der ['Preis', 'Job', 'Platz', 'Service', 'Abend', 'Wind', 'Rest', 'Sieg', 'Auftritt', 'Eindruck']\n",
      "Der ['Rest', 'Job', 'Film', 'Ton', 'Fußball', 'Mann', 'Preis', 'Markt', 'Anfang', 'Fall']\n",
      "Die ['Stimmung', 'Atmosphäre', 'Situation', 'Sache', 'Resonanz', 'Lage', 'Idee', 'Antwort', 'Qualität', 'Zusammenarbeit']\n",
      "Die ['Stimmung', 'Sache', 'Situation', 'Lage', 'Welt', 'Idee', 'Musik', 'Antwort', 'Geschichte', 'Zeit']\n",
      "Das ['Ergebnis', 'Wetter', 'alles', 'Leben', 'Angebot', 'hier', 'Spiel', 'Resultat', 'Stadion', 'Essen']\n",
      "Das ['Ergebnis', 'alles', 'Wetter', 'Leben', 'aber', 'Spiel', 'Ganze', 'hier', 'Auto', 'Geschäft']\n"
     ]
    }
   ],
   "source": [
    "# get noun suggestions from the CheckList Editors in German and English\n",
    "# english suggestions\n",
    "print(\"English noun suggestions: \")\n",
    "print(eng_editor.suggest(\"This {mask} is {pos}.\", pos=eng_pos)[:10]) \n",
    "print(eng_editor.suggest(\"This {mask} is {neg}.\", neg=eng_neg)[:10], \"\\n\") \n",
    "\n",
    "# suggestions for standard German with different determiners\n",
    "print(\"German noun suggestions: \")\n",
    "print(\"Der\", deu_editor.suggest(\"Der {mask} ist {pos}.\", pos=deu_pos)[:10])\n",
    "print(\"Der\", deu_editor.suggest(\"Der {mask} ist {neg}.\", neg=deu_neg)[:10])\n",
    "print(\"Die\", deu_editor.suggest(\"Die {mask} ist {pos}.\", pos=deu_pos)[:10])\n",
    "print(\"Die\", deu_editor.suggest(\"Die {mask} ist {neg}.\", neg=deu_neg)[:10])\n",
    "print(\"Das\", deu_editor.suggest(\"Das {mask} ist {pos}.\", pos=deu_pos)[:10])\n",
    "print(\"Das\", deu_editor.suggest(\"Das {mask} ist {neg}.\", neg=deu_neg)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel noun lists for data creation\n",
    "# picked from Editor suggestions in such a way that mostly all words are different\n",
    "eng_noun = [\"game\", \"site\", \"picture\", \"book\", \"story\", \"man\", \"world\", \"city\", \"time\", \"weather\", \"life\"]\n",
    "\n",
    "# standard German and Bavarian examples with determiners to avoid errors\n",
    "deu_noun = [\n",
    "    (\"Das\", \"Spiel\"), (\"Die\", \"Seite\"), (\"Das\", \"Bild\"), (\"Das\", \"Buch\"), (\"Die\", \"Geschichte\"), \n",
    "    (\"Der\", \"Mann\"), (\"Die\", \"Welt\"), (\"Die\", \"Stadt\"), (\"Die\", \"Zeit\"), (\"Das\", \"Wetter\"), (\"Das\", \"Leben\")\n",
    "    ]\n",
    "\n",
    "# bavarian determiners are with spaces to handle \"d'\" and \"s'\" determiners\n",
    "bar_noun = [\n",
    "    (\"Des \", \"Spui\"), (\"De \", \"Seitn\"), (\"Des \", \"Buidl\"), (\"Des \", \"Buach\"), (\"De \", \"Gschicht\"), \n",
    "    (\"Der \", \"Mo\"), (\"D'\", \"Weid\"), (\"D'\", \"Stod\"), (\"D'\", \"Zeid\"), (\"S'\", \"Weda\"), (\"S'\", \"Lebm\")\n",
    "    ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create english data\n",
    "eng = eng_editor.template(\"The {noun} is not {adj}.\", noun=eng_noun, adj=eng_pos, labels=0) # not pos = negative\n",
    "eng += eng_editor.template(\"The {noun} is not {adj}.\", noun=eng_noun, adj=eng_neg, labels=1) # not neg = positive\n",
    "\n",
    "# create german data\n",
    "deu = deu_editor.template(\"{detnoun[0]} {detnoun[1]} ist nicht {adj}.\", detnoun=deu_noun, adj=deu_pos, labels=0)\n",
    "deu += deu_editor.template(\"{detnoun[0]} {detnoun[1]} ist nicht {adj}.\", detnoun=deu_noun, adj=deu_neg, labels=1)\n",
    "\n",
    "# create bavarian data\n",
    "bar = deu_editor.template(\"{detnoun[0]}{detnoun[1]} is ned {adj}.\", detnoun=bar_noun, adj=bar_pos, labels=0)\n",
    "bar += deu_editor.template(\"{detnoun[0]}{detnoun[1]} is ned {adj}.\", detnoun=bar_noun, adj=bar_neg, labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Des Spui is ned guad.', 'Des Spui is ned schee.', 'Des Spui is ned subba.', 'De Seitn is ned guad.', 'De Seitn is ned schee.', 'De Seitn is ned subba.', 'Des Buidl is ned guad.', 'Des Buidl is ned schee.', 'Des Buidl is ned subba.', 'Des Buach is ned guad.', 'Des Buach is ned schee.', 'Des Buach is ned subba.', 'De Gschicht is ned guad.', 'De Gschicht is ned schee.', 'De Gschicht is ned subba.', 'Der Mo is ned guad.', 'Der Mo is ned schee.', 'Der Mo is ned subba.', \"D'Weid is ned guad.\", \"D'Weid is ned schee.\", \"D'Weid is ned subba.\", \"D'Stod is ned guad.\", \"D'Stod is ned schee.\", \"D'Stod is ned subba.\", \"D'Zeid is ned guad.\", \"D'Zeid is ned schee.\", \"D'Zeid is ned subba.\", \"S'Weda is ned guad.\", \"S'Weda is ned schee.\", \"S'Weda is ned subba.\", \"S'Lebm is ned guad.\", \"S'Lebm is ned schee.\", \"S'Lebm is ned subba.\", 'Des Spui is ned schlecht.', 'Des Spui is ned fad.', 'Des Spui is ned bled.', 'De Seitn is ned schlecht.', 'De Seitn is ned fad.', 'De Seitn is ned bled.', 'Des Buidl is ned schlecht.', 'Des Buidl is ned fad.', 'Des Buidl is ned bled.', 'Des Buach is ned schlecht.', 'Des Buach is ned fad.', 'Des Buach is ned bled.', 'De Gschicht is ned schlecht.', 'De Gschicht is ned fad.', 'De Gschicht is ned bled.', 'Der Mo is ned schlecht.', 'Der Mo is ned fad.', 'Der Mo is ned bled.', \"D'Weid is ned schlecht.\", \"D'Weid is ned fad.\", \"D'Weid is ned bled.\", \"D'Stod is ned schlecht.\", \"D'Stod is ned fad.\", \"D'Stod is ned bled.\", \"D'Zeid is ned schlecht.\", \"D'Zeid is ned fad.\", \"D'Zeid is ned bled.\", \"S'Weda is ned schlecht.\", \"S'Weda is ned fad.\", \"S'Weda is ned bled.\", \"S'Lebm is ned schlecht.\", \"S'Lebm is ned fad.\", \"S'Lebm is ned bled.\"]\n"
     ]
    }
   ],
   "source": [
    "# initialise minimum functionality tests\n",
    "eng_test = MFT(**eng, name=\"English Negations\", capability=\"Negation\", description=\"Litotes sentences to test negation capabilities.\")\n",
    "deu_test = MFT(**deu, name=\"Standard German Negations\", capability=\"Negation\", description=\"Litotes sentences to test negation capabilities.\")\n",
    "bar_test = MFT(**bar, name=\"Bavarian Negations\", capability=\"Negation\", description=\"Litotes sentences to test negation capabilities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "/home/miriam/Music/trustenv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load finetuned mBERT for sentiment analysis\n",
    "model_name = \"./models/mBERT_sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# initialise pipeline for predictions\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "# make predictions on test data\n",
    "lbl2idx = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "def predict(test):\n",
    "    # read data and predict\n",
    "    data = test.to_raw_examples() # necessary for internal CheckList structures (self.result_indexes)\n",
    "    raw_preds = pipe(data)\n",
    "\n",
    "    preds = []\n",
    "    confs = []\n",
    "\n",
    "    # write results in correct CheckList format to a file\n",
    "    for result in raw_preds:\n",
    "        negative = result[0]\n",
    "        neutral = result[1]\n",
    "        positive = result[2]\n",
    "\n",
    "        max_pred = max([negative, neutral, positive], key=lambda x: x[\"score\"])\n",
    "        max_label = max_pred[\"label\"]\n",
    "\n",
    "        # prediction, negative_score, neutral_score, positive_score\n",
    "        preds.append(lbl2idx[max_label])\n",
    "        confs.append(np.array([negative[\"score\"], neutral[\"score\"], positive[\"score\"]]))\n",
    "\n",
    "    return preds, confs\n",
    "\n",
    "eng_preds, eng_confs = predict(eng_test)\n",
    "deu_preds, deu_confs = predict(deu_test)\n",
    "bar_preds, bar_confs = predict(bar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      66\n",
      "Fails (rate):    54 (81.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.1 0.0 The game is not stupid.\n",
      "----\n",
      "0.9 0.1 0.0 The book is not stupid.\n",
      "----\n",
      "0.6 0.3 0.1 The world is not boring.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "eng_test.run_from_preds_confs(eng_preds, eng_confs, overwrite=True)\n",
    "\n",
    "eng_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      66\n",
      "Fails (rate):    34 (51.5%)\n",
      "\n",
      "Example fails:\n",
      "0.8 0.2 0.1 Das Leben ist nicht schlecht.\n",
      "----\n",
      "0.6 0.3 0.1 Das Leben ist nicht langweilig.\n",
      "----\n",
      "0.5 0.4 0.1 Das Bild ist nicht langweilig.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "deu_test.run_from_preds_confs(deu_preds, deu_confs, overwrite=True)\n",
    "\n",
    "deu_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      66\n",
      "Fails (rate):    34 (51.5%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.2 0.1 D'Weid is ned bled.\n",
      "----\n",
      "0.5 0.3 0.2 Des Buach is ned fad.\n",
      "----\n",
      "0.8 0.1 0.1 S'Lebm is ned schlecht.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "bar_test.run_from_preds_confs(bar_preds, bar_confs, overwrite=True)\n",
    "\n",
    "bar_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0, 2, 2, 0, 2]\n",
      "Confidences: [array([0.44630149, 0.25521377, 0.29848468]), array([0.17414553, 0.14964208, 0.67621237]), array([0.28616518, 0.242695  , 0.47113985]), array([0.46459395, 0.29296777, 0.24243827]), array([0.23632866, 0.1914082 , 0.57226312])]\n",
      "len preds:  66\n",
      "len confs:  66\n",
      "Test cases:      66\n",
      "Fails (rate):    54 (81.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.1 0.0 The game is not stupid.\n",
      "----\n",
      "0.2 0.2 0.6 The picture is not nice.\n",
      "----\n",
      "0.2 0.2 0.6 The city is not nice.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# from checklist.test_types import MFT\n",
    "# import numpy as np\n",
    "\n",
    "# eng_test = MFT(**eng, name=\"English Negations\", capability=\"Negation\", description=\"Litotes sentences to test negation capabilities.\")\n",
    "\n",
    "# eng_data = eng_test.to_raw_examples()\n",
    "\n",
    "# # with open(raw_file_path, \"r\") as f:\n",
    "# #     eng_data = f.read().splitlines()\n",
    "\n",
    "# raw_preds = pipe(eng_data)\n",
    "# preds = []\n",
    "# confs = []\n",
    "\n",
    "# for result in raw_preds:\n",
    "#     negative = result[0]\n",
    "#     neutral = result[1]\n",
    "#     positive = result[2]\n",
    "\n",
    "#     max_pred = max([negative, neutral, positive], key=lambda x: x[\"score\"])\n",
    "#     max_label = max_pred[\"label\"]\n",
    "\n",
    "#     # prediction, negative_score, neutral_score, positive_score\n",
    "#     preds.append(lbl2idx[max_label])\n",
    "#     confs.append(np.array([negative[\"score\"], neutral[\"score\"], positive[\"score\"]]))\n",
    "\n",
    "\n",
    "# from checklist.abstract_test import read_pred_file\n",
    "# from checklist.test_types import MFT\n",
    "\n",
    "# # Assuming eng_test is already created as an MFT instance\n",
    "\n",
    "# # Read predictions and confidences from the file\n",
    "# # preds, confs = read_pred_file(\"/tmp/preds_eng.txt\", file_format=\"softmax\")\n",
    "\n",
    "# # Verify the parsed predictions and confidences\n",
    "# print(\"Predictions:\", preds[:5])\n",
    "# print(\"Confidences:\", confs[:5])\n",
    "\n",
    "# print(\"len preds: \", len(preds))\n",
    "# print(\"len confs: \", len(confs))\n",
    "\n",
    "# if preds is None or confs is None:\n",
    "#     print(\"Error: The predictions or confidences are None. Please check the file format.\")\n",
    "\n",
    "# # Run the test using the loaded predictions and confidences\n",
    "# eng_test.run_from_preds_confs(preds, confs, overwrite=True)\n",
    "\n",
    "# # Print the summary of the results\n",
    "# eng_test.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
